{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Polinómica vs Splines vs Natural Splines en Python\n",
    "\n",
    "En este notebook replicamos el análisis del script R que compara diferentes técnicas de regresión no lineal.\n",
    "\n",
    "**Objetivo**: Comparar el desempeño de diferentes enfoques de regresión no paramétrica:\n",
    "- Regresión polinómica\n",
    "- Regresión lineal local (por segmentos)\n",
    "- Regresión por partes (Piecewise/Broken Stick Regression)\n",
    "- Splines cúbicas (B-splines)\n",
    "- Natural Splines\n",
    "\n",
    "**Dataset**: `mcycle` de la librería MASS de R - datos de aceleración de cabeza en accidentes de motocicleta.\n",
    "\n",
    "Referencia: Ripley (2002): \"Modern Applied Statistics with S-PLUS\". Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Splines\n",
    "from scipy.interpolate import BSpline, splrep, splev\n",
    "from patsy import dmatrix, build_design_matrices\n",
    "\n",
    "# Configuración de gráficos\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Desactivar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga del Dataset `mcycle`\n",
    "\n",
    "El dataset **mcycle** contiene mediciones de aceleración de la cabeza en una simulación de accidente de motocicleta.\n",
    "\n",
    "**Variables**:\n",
    "- `times`: Tiempo después del impacto (milisegundos)\n",
    "- `accel`: Aceleración de la cabeza (unidades de gravedad, g)\n",
    "\n",
    "El dataset contiene 133 observaciones y es comúnmente usado para ilustrar técnicas de regresión no lineal debido a su relación compleja y no monotónica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset desde URL pública\n",
    "url = \"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/MASS/mcycle.csv\"\n",
    "mcycle = pd.read_csv(url)\n",
    "\n",
    "# Eliminar columna de índice si existe\n",
    "if 'Unnamed: 0' in mcycle.columns:\n",
    "    mcycle = mcycle.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Renombrar columnas si es necesario para consistencia\n",
    "if 'rownames' in mcycle.columns:\n",
    "    mcycle = mcycle.drop('rownames', axis=1)\n",
    "\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "print(mcycle.head())\n",
    "print(f\"\\nDimensiones del dataset: {mcycle.shape}\")\n",
    "print(f\"\\nEstadísticas descriptivas:\")\n",
    "print(mcycle.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualización Inicial de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer variables\n",
    "times = mcycle['times'].values\n",
    "accel = mcycle['accel'].values\n",
    "\n",
    "# Gráfico de dispersión\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.7, s=50, edgecolors='none')\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title('Dataset mcycle: Aceleración vs Tiempo', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regresión Polinómica (Grado 9)\n",
    "\n",
    "La **regresión polinómica** extiende la regresión lineal al agregar términos de potencias superiores de las variables predictoras.\n",
    "\n",
    "**Modelo**: $y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ... + \\beta_9 x^9 + \\epsilon$\n",
    "\n",
    "**Ventajas**:\n",
    "- Fácil de implementar\n",
    "- Modelo global (una función para todo el dominio)\n",
    "\n",
    "**Desventajas**:\n",
    "- Puede generar sobreajuste\n",
    "- Comportamiento errático en los extremos\n",
    "- No es local (un cambio en los datos afecta toda la curva)\n",
    "\n",
    "La función `PolynomialFeatures` construye la matriz de diseño con términos polinómicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear características polinómicas de grado 9\n",
    "poly_features = PolynomialFeatures(degree=9, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(times.reshape(-1, 1))\n",
    "\n",
    "print(\"Matriz de diseño polinómica (primeras 5 filas):\")\n",
    "print(pd.DataFrame(X_poly[:5], columns=[f'times^{i+1}' for i in range(9)]))\n",
    "print(f\"\\nDimensiones de la matriz de diseño: {X_poly.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo de regresión polinómica\n",
    "poly9_model = LinearRegression()\n",
    "poly9_model.fit(X_poly, accel)\n",
    "\n",
    "# Predicciones\n",
    "poly9_pred = poly9_model.predict(X_poly)\n",
    "\n",
    "# Resumen del modelo\n",
    "r2_poly = r2_score(accel, poly9_pred)\n",
    "mse_poly = mean_squared_error(accel, poly9_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL MODELO - REGRESIÓN POLINÓMICA (GRADO 9)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"R² (coeficiente de determinación): {r2_poly:.4f}\")\n",
    "print(f\"MSE (error cuadrático medio): {mse_poly:.4f}\")\n",
    "print(f\"\\nCoeficientes del modelo:\")\n",
    "for i, coef in enumerate(poly9_model.coef_):\n",
    "    print(f\"  β_{i+1} (times^{i+1}): {coef:.6e}\")\n",
    "print(f\"  β_0 (intercepto): {poly9_model.intercept_:.6f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la regresión polinómica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.7, s=50, label='Datos observados')\n",
    "plt.plot(times, poly9_pred, color='blue', alpha=0.6, linewidth=3, \n",
    "         linestyle='--', label='Regresión Polinómica (grado 9)')\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title('Regresión Polinómica (Grado 9)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regresión Lineal Local (por segmentos)\n",
    "\n",
    "Una alternativa simple es ajustar **modelos lineales independientes** en diferentes regiones del dominio.\n",
    "\n",
    "**Enfoque**: Dividir el rango de `times` en 5 segmentos y ajustar una regresión lineal en cada uno:\n",
    "1. times ≤ 15\n",
    "2. 15 < times ≤ 22\n",
    "3. 22 < times ≤ 35\n",
    "4. 35 < times ≤ 50\n",
    "5. times > 50\n",
    "\n",
    "**Problema**: Las funciones resultantes no son continuas en los puntos de corte (\"knots\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los segmentos\n",
    "segments = [\n",
    "    (times <= 15, 'times ≤ 15'),\n",
    "    ((times > 15) & (times <= 22), '15 < times ≤ 22'),\n",
    "    ((times > 22) & (times <= 35), '22 < times ≤ 35'),\n",
    "    ((times > 35) & (times <= 50), '35 < times ≤ 50'),\n",
    "    (times > 50, 'times > 50')\n",
    "]\n",
    "\n",
    "# Ajustar modelos lineales para cada segmento\n",
    "local_models = []\n",
    "local_preds = []\n",
    "\n",
    "for mask, label in segments:\n",
    "    if np.sum(mask) > 0:  # Verificar que hay datos en el segmento\n",
    "        X_seg = times[mask].reshape(-1, 1)\n",
    "        y_seg = accel[mask]\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_seg, y_seg)\n",
    "        pred = model.predict(X_seg)\n",
    "        \n",
    "        local_models.append((mask, model, label))\n",
    "        local_preds.append((X_seg.flatten(), pred))\n",
    "        \n",
    "        print(f\"{label}: β_0 = {model.intercept_:.3f}, β_1 = {model.coef_[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de regresión lineal local\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.7, s=50, label='Datos observados')\n",
    "\n",
    "# Graficar cada segmento\n",
    "for X_seg, pred in local_preds:\n",
    "    plt.plot(X_seg, pred, color='red', alpha=0.6, linewidth=3, linestyle='--')\n",
    "\n",
    "# Crear una sola etiqueta para la leyenda\n",
    "plt.plot([], [], color='red', alpha=0.6, linewidth=3, \n",
    "         linestyle='--', label='Regresión lineal local (5 segmentos)')\n",
    "\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title('Regresión Lineal Local por Segmentos', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regresión por Partes (Piecewise / Broken Stick Regression)\n",
    "\n",
    "La **regresión por partes** mejora la regresión lineal local al garantizar **continuidad** en los knots.\n",
    "\n",
    "**Modelo aditivo**: Se usa una base de funciones tipo \"bisagra\" (hinge functions):\n",
    "\n",
    "$$f(x) = \\beta_0 + \\beta_1 x + \\beta_2 (x - \\nu_1)_+ + \\beta_3 (x - \\nu_2)_+ + ... + \\beta_k (x - \\nu_k)_+$$\n",
    "\n",
    "donde $(x - \\nu)_+ = \\max(0, x - \\nu)$ es la función \"parte positiva\".\n",
    "\n",
    "**Knots utilizados**: $\\nu = \\{15, 22, 35, 50\\}$\n",
    "\n",
    "**Ventaja**: La función resultante es continua pero no diferenciable en los knots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los knots\n",
    "knots = [15, 22, 35, 50]\n",
    "\n",
    "# Crear matriz de diseño para regresión por partes\n",
    "def create_piecewise_features(x, knots):\n",
    "    \"\"\"Crea matriz de diseño con funciones hinge (x - knot)_+\"\"\"\n",
    "    X = np.column_stack([x] + [np.maximum(0, x - k) for k in knots])\n",
    "    return X\n",
    "\n",
    "X_piecewise = create_piecewise_features(times, knots)\n",
    "\n",
    "print(\"Matriz de diseño para regresión por partes (primeras 5 filas):\")\n",
    "feature_names = ['times'] + [f'(times-{k})_+' for k in knots]\n",
    "print(pd.DataFrame(X_piecewise[:5], columns=feature_names))\n",
    "print(f\"\\nDimensiones: {X_piecewise.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo de regresión por partes\n",
    "piecewise_model = LinearRegression()\n",
    "piecewise_model.fit(X_piecewise, accel)\n",
    "\n",
    "# Predicciones\n",
    "piecewise_pred = piecewise_model.predict(X_piecewise)\n",
    "\n",
    "# Resumen del modelo\n",
    "r2_piecewise = r2_score(accel, piecewise_pred)\n",
    "mse_piecewise = mean_squared_error(accel, piecewise_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL MODELO - REGRESIÓN POR PARTES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"R² (coeficiente de determinación): {r2_piecewise:.4f}\")\n",
    "print(f\"MSE (error cuadrático medio): {mse_piecewise:.4f}\")\n",
    "print(f\"\\nCoeficientes del modelo:\")\n",
    "print(f\"  β_0 (intercepto): {piecewise_model.intercept_:.4f}\")\n",
    "for i, (name, coef) in enumerate(zip(feature_names, piecewise_model.coef_)):\n",
    "    print(f\"  β_{i+1} ({name}): {coef:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de regresión por partes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.7, s=50, label='Datos observados')\n",
    "plt.plot(times, piecewise_pred, color='green', alpha=0.6, linewidth=3, \n",
    "         linestyle='--', label='Regresión por partes')\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title('Regresión por Partes (Broken Stick)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Splines Cúbicas (B-splines de grado 3)\n",
    "\n",
    "Los **splines cúbicos** son funciones polinómicas por partes que garantizan continuidad y diferenciabilidad.\n",
    "\n",
    "**Propiedades**:\n",
    "- Polinomios de grado 3 entre cada par de knots\n",
    "- Continuidad de la función: $f(x)$\n",
    "- Continuidad de la primera derivada: $f'(x)$\n",
    "- Continuidad de la segunda derivada: $f''(x)$\n",
    "\n",
    "**B-splines**: Bases de splines que forman una base computacionalmente estable.\n",
    "\n",
    "La función `bs()` de `patsy` construye la matriz de diseño con bases B-spline, similar a la función `bs()` de R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de diseño con B-splines usando patsy\n",
    "# La sintaxis bs(x, knots=..., degree=3) es equivalente a la de R\n",
    "spline_basis = dmatrix(\"bs(times, knots=knots, degree=3, include_intercept=False)\", \n",
    "                       {\"times\": times, \"knots\": knots}, \n",
    "                       return_type='dataframe')\n",
    "\n",
    "print(\"Matriz de diseño con B-splines (primeras 5 filas):\")\n",
    "print(spline_basis.head())\n",
    "print(f\"\\nDimensiones: {spline_basis.shape}\")\n",
    "print(f\"\\nNúmero de bases: {spline_basis.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo de splines cúbicas\n",
    "spline_model = LinearRegression()\n",
    "spline_model.fit(spline_basis, accel)\n",
    "\n",
    "# Predicciones\n",
    "spline_pred = spline_model.predict(spline_basis)\n",
    "\n",
    "# Resumen del modelo\n",
    "r2_spline = r2_score(accel, spline_pred)\n",
    "mse_spline = mean_squared_error(accel, spline_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL MODELO - SPLINES CÚBICAS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"R² (coeficiente de determinación): {r2_spline:.4f}\")\n",
    "print(f\"MSE (error cuadrático medio): {mse_spline:.4f}\")\n",
    "print(f\"\\nCoeficientes del modelo:\")\n",
    "print(f\"  β_0 (intercepto): {spline_model.intercept_:.4f}\")\n",
    "for i, coef in enumerate(spline_model.coef_):\n",
    "    print(f\"  β_{i+1}: {coef:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de splines cúbicas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.7, s=50, label='Datos observados')\n",
    "plt.plot(times, spline_pred, color='brown', alpha=0.8, linewidth=3, \n",
    "         linestyle='--', label='Splines cúbicas (B-splines)')\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title('Regresión con Splines Cúbicas (degree=3)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Natural Splines\n",
    "\n",
    "Los **natural splines** son splines cúbicos con restricciones adicionales en los extremos.\n",
    "\n",
    "**Restricción**: En las regiones más allá de los knots extremos (bordes), la función es lineal.\n",
    "- Para $x < \\nu_1$ (primer knot): $f''(x) = 0$ → función lineal\n",
    "- Para $x > \\nu_k$ (último knot): $f''(x) = 0$ → función lineal\n",
    "\n",
    "**Ventaja**: Reduce el sobreajuste en los extremos del dominio, donde típicamente hay menos datos.\n",
    "\n",
    "La función `cr()` de `patsy` crea bases de natural splines (cubic regression splines), equivalente a `ns()` en R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de diseño con Natural Splines usando patsy\n",
    "# cr() en patsy es equivalente a ns() en R\n",
    "nat_spline_basis = dmatrix(\"cr(times, knots=knots)\", \n",
    "                           {\"times\": times, \"knots\": knots}, \n",
    "                           return_type='dataframe')\n",
    "\n",
    "print(\"Matriz de diseño con Natural Splines (primeras 5 filas):\")\n",
    "print(nat_spline_basis.head())\n",
    "print(f\"\\nDimensiones: {nat_spline_basis.shape}\")\n",
    "print(f\"\\nNúmero de bases: {nat_spline_basis.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo de natural splines\n",
    "nat_spline_model = LinearRegression()\n",
    "nat_spline_model.fit(nat_spline_basis, accel)\n",
    "\n",
    "# Predicciones\n",
    "nat_spline_pred = nat_spline_model.predict(nat_spline_basis)\n",
    "\n",
    "# Resumen del modelo\n",
    "r2_nat = r2_score(accel, nat_spline_pred)\n",
    "mse_nat = mean_squared_error(accel, nat_spline_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL MODELO - NATURAL SPLINES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"R² (coeficiente de determinación): {r2_nat:.4f}\")\n",
    "print(f\"MSE (error cuadrático medio): {mse_nat:.4f}\")\n",
    "print(f\"\\nCoeficientes del modelo:\")\n",
    "print(f\"  β_0 (intercepto): {nat_spline_model.intercept_:.4f}\")\n",
    "for i, coef in enumerate(nat_spline_model.coef_):\n",
    "    print(f\"  β_{i+1}: {coef:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de natural splines\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.7, s=50, label='Datos observados')\n",
    "plt.plot(times, nat_spline_pred, color='orange', alpha=0.8, linewidth=3, \n",
    "         linestyle='--', label='Natural Splines')\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title('Regresión con Natural Splines', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNota: Observa cómo la función se comporta de forma lineal en los bordes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualización Comparativa (estilo ggplot2)\n",
    "\n",
    "Comparación visual de los tres métodos principales:\n",
    "- Regresión polinómica (grado 9) - azul\n",
    "- Splines cúbicas - marrón\n",
    "- Natural splines - naranja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico comparativo estilo ggplot2 con theme_minimal\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Datos observados\n",
    "plt.scatter(times, accel, color='black', alpha=0.55, s=50, \n",
    "           label='Datos observados', zorder=5)\n",
    "\n",
    "# Ordenar los datos para graficar líneas suaves\n",
    "sort_idx = np.argsort(times)\n",
    "times_sorted = times[sort_idx]\n",
    "\n",
    "# Regresión polinómica\n",
    "plt.plot(times_sorted, poly9_pred[sort_idx], color='blue', \n",
    "         linewidth=2.5, label='Regresión Polinómica (grado 9)', alpha=0.8)\n",
    "\n",
    "# Splines cúbicas\n",
    "plt.plot(times_sorted, spline_pred[sort_idx], color='brown', \n",
    "         linewidth=2.5, label='Splines Cúbicas', alpha=0.8)\n",
    "\n",
    "# Natural splines\n",
    "plt.plot(times_sorted, nat_spline_pred[sort_idx], color='orange', \n",
    "         linewidth=2.5, label='Natural Splines', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=13)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=13)\n",
    "plt.title('Comparación de Métodos de Regresión No Lineal', \n",
    "         fontsize=15, fontweight='bold', pad=15)\n",
    "plt.legend(fontsize=11, loc='best', framealpha=0.9)\n",
    "plt.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla Comparativa de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa de métricas\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Método': ['Regresión Polinómica (grado 9)', 'Regresión por Partes', \n",
    "               'Splines Cúbicas', 'Natural Splines'],\n",
    "    'R²': [r2_poly, r2_piecewise, r2_spline, r2_nat],\n",
    "    'MSE': [mse_poly, mse_piecewise, mse_spline, mse_nat]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARACIÓN DE MÉTRICAS DE LOS MODELOS\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nObservaciones:\")\n",
    "print(\"- R² más alto indica mejor ajuste a los datos de entrenamiento\")\n",
    "print(\"- MSE más bajo indica menores errores de predicción\")\n",
    "print(\"- Sin embargo, R² alto puede indicar sobreajuste si no se valida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "Para seleccionar el **número óptimo de grados de libertad (df)** en splines, usamos validación cruzada.\n",
    "\n",
    "**Leave-One-Out CV**:\n",
    "1. Para cada observación $i$:\n",
    "   - Entrenar el modelo con todas las observaciones excepto $i$\n",
    "   - Predecir el valor de $i$\n",
    "   - Calcular el error cuadrático\n",
    "2. Promediar los errores sobre todas las observaciones\n",
    "\n",
    "**Ventaja**: Usa todos los datos para entrenamiento (excepto uno), maximizando el uso de información.\n",
    "\n",
    "**Desventaja**: Computacionalmente costoso (N iteraciones).\n",
    "\n",
    "Probaremos modelos con df (degrees of freedom) de 3 a 15 y seleccionaremos el que minimice el error LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOCV para seleccionar grados de libertad óptimos\n",
    "df_range = range(3, 16)  # df de 3 a 15\n",
    "cv_errors = []\n",
    "\n",
    "print(\"Ejecutando Leave-One-Out Cross-Validation...\")\n",
    "print(\"df\\tMSE (LOOCV)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for df in df_range:\n",
    "    # Crear modelo con df grados de libertad\n",
    "    # df en bs() controla el número de bases (knots se colocan automáticamente)\n",
    "    spline_basis_df = dmatrix(f\"bs(times, df={df}, degree=3, include_intercept=False)\", \n",
    "                               {\"times\": times}, \n",
    "                               return_type='dataframe')\n",
    "    \n",
    "    # LOOCV\n",
    "    loo = LeaveOneOut()\n",
    "    mse_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in loo.split(spline_basis_df):\n",
    "        # Split train/test\n",
    "        X_train, X_test = spline_basis_df.iloc[train_idx], spline_basis_df.iloc[test_idx]\n",
    "        y_train, y_test = accel[train_idx], accel[test_idx]\n",
    "        \n",
    "        # Entrenar y predecir\n",
    "        model_cv = LinearRegression()\n",
    "        model_cv.fit(X_train, y_train)\n",
    "        y_pred = model_cv.predict(X_test)\n",
    "        \n",
    "        # Error cuadrático\n",
    "        mse_scores.append((y_test[0] - y_pred[0])**2)\n",
    "    \n",
    "    # MSE promedio\n",
    "    cv_mse = np.mean(mse_scores)\n",
    "    cv_errors.append(cv_mse)\n",
    "    print(f\"{df}\\t{cv_mse:.2f}\")\n",
    "\n",
    "# Encontrar df óptimo\n",
    "optimal_df = df_range[np.argmin(cv_errors)]\n",
    "min_error = np.min(cv_errors)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\nGrados de libertad óptimos: {optimal_df}\")\n",
    "print(f\"MSE mínimo (LOOCV): {min_error:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de errores LOOCV\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_range, cv_errors, 'o-', linewidth=2.5, markersize=8, color='darkblue')\n",
    "plt.axvline(x=optimal_df, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'df óptimo = {optimal_df}')\n",
    "plt.xlabel('Grados de Libertad (df)', fontsize=12)\n",
    "plt.ylabel('MSE (Leave-One-Out CV)', fontsize=12)\n",
    "plt.title('Selección de Grados de Libertad mediante LOOCV', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste Final con df Óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo final con df óptimo\n",
    "spline_basis_optimal = dmatrix(f\"bs(times, df={optimal_df}, degree=3, include_intercept=False)\", \n",
    "                               {\"times\": times}, \n",
    "                               return_type='dataframe')\n",
    "\n",
    "spline_optimal_model = LinearRegression()\n",
    "spline_optimal_model.fit(spline_basis_optimal, accel)\n",
    "spline_optimal_pred = spline_optimal_model.predict(spline_basis_optimal)\n",
    "\n",
    "r2_optimal = r2_score(accel, spline_optimal_pred)\n",
    "mse_optimal = mean_squared_error(accel, spline_optimal_pred)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"MODELO ÓPTIMO - SPLINES CON df={optimal_df}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"R² (coeficiente de determinación): {r2_optimal:.4f}\")\n",
    "print(f\"MSE (error en conjunto de entrenamiento): {mse_optimal:.4f}\")\n",
    "print(f\"MSE (estimado por LOOCV): {min_error:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo óptimo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(times, accel, color='black', alpha=0.6, s=50, label='Datos observados')\n",
    "plt.plot(times_sorted, spline_optimal_pred[sort_idx], color='darkgreen', \n",
    "         linewidth=3, label=f'Spline óptima (df={optimal_df})', alpha=0.9)\n",
    "plt.xlabel('Tiempo después del impacto (ms)', fontsize=12)\n",
    "plt.ylabel('Aceleración de la cabeza (g)', fontsize=12)\n",
    "plt.title(f'Modelo Óptimo: Spline Cúbica con df={optimal_df}', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusiones\n",
    "\n",
    "En este notebook hemos replicado el análisis del script R comparando diferentes técnicas de regresión no lineal:\n",
    "\n",
    "### Resumen de Métodos:\n",
    "\n",
    "1. **Regresión Polinómica**: Simple pero propensa a sobreajuste y comportamiento errático en los extremos.\n",
    "\n",
    "2. **Regresión Lineal Local**: Fácil de interpretar pero discontinua en los knots.\n",
    "\n",
    "3. **Regresión por Partes**: Garantiza continuidad pero no diferenciabilidad.\n",
    "\n",
    "4. **Splines Cúbicas**: Continuas y dos veces diferenciables, excelente balance entre flexibilidad y suavidad.\n",
    "\n",
    "5. **Natural Splines**: Como splines cúbicas pero con restricciones lineales en los bordes para reducir sobreajuste.\n",
    "\n",
    "### Ventajas de Splines:\n",
    "- Flexibilidad local: cambios en una región no afectan regiones lejanas\n",
    "- Continuidad y diferenciabilidad\n",
    "- Comportamiento estable en los extremos (natural splines)\n",
    "- Se pueden optimizar vía cross-validación\n",
    "\n",
    "### Cross-Validación:\n",
    "Leave-One-Out CV permite seleccionar el número óptimo de grados de libertad, balanceando:\n",
    "- **Sesgo**: df muy bajo → modelo demasiado simple (underfitting)\n",
    "- **Varianza**: df muy alto → modelo demasiado complejo (overfitting)\n",
    "\n",
    "---\n",
    "\n",
    "**Referencias**:\n",
    "- Ripley, B. D. (2002). Modern Applied Statistics with S-PLUS. Springer.\n",
    "- Hastie, T., Tibshirani, R., & Friedman, J. (2009). The Elements of Statistical Learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
